{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using UNET for data segmentation\n",
    "\n",
    "UNET es una red neuronal profunda utilizada para la segmentacion de imagenes, nacida para propositos biomedicos, la imagen de entrada es procesada mediante un codificador convolucional, hasta saturarla en las capas intermedias. Acto seguido, un decodificador convolucional convierte la imagen en una mascara mediante discriminacion cada una de las clases.\n",
    "\n",
    "Aqui podemos ver la arquitectura de la red:\n",
    "![U-Net architechture](images/u-net-architecture.png)\n",
    "\n",
    "En esta implementacion, se realiza una adaptacion de la red para un dataset de imagenes de carreteras extraida de las camaras de varios coches autonomos.\n",
    "\n",
    "Dicho dataset es accesible y descargable desde http://www.tromai.icoc.me/ y cargado y preprocesado mediante el metodo load_data del archivo loader.py\n",
    "\n",
    "Este dataset contiene 20 clases etiquetadas cuyo groundtruth contiene las mascaras de las mismas. Las 20 clases son:\n",
    "![Dataset Classes](images/dataset_classes.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Loads data into numpy arrays ready for Keras training / testing\n",
      "    Returns: Tuple with train and test datasets\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from loader import load_data\n",
    "print(load_data.__doc__)\n",
    "(X_train, y_train, X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ha sido cargado el dataset, podemos ver las imagenes y las marcas mediante el uso de matplotlib, como podemos ver, la categorizacion final se realiza mediante el uso de la funcion argmax de la libreria numpy, que nos devuelve la clase dominante en cada pixel de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_train[300])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.argmax(y_train[300], axis=2))\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1,2,1);\n",
    "plt.imshow(X_train[20]);\n",
    "plt.subplot(1,2,2);\n",
    "plt.imshow(np.argmax(y_train[20], axis=2))\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red neuronal profunda utilizada ha sido extraida de https://github.com/petrosgk/Kaggle-Carvana-Image-Masking-Challenge, dicha red y los losses utilizados para el entrenamiento podemos encontrarla en los archivos recogidos en la carpeta model/, en el siguiente paso, realizamos la carga de la misma, concretamente de la red cuyo tamaño de entrada coincide con el de las imagenes del dataset utilizado, la topologia es volcada a un fichero JSON para el uso de la red en produccion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.u_net import get_unet_128 as unet\n",
    "\n",
    "model = unet(num_classes=20)\n",
    "print(model.summary())\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los datos y la red preparados, podemos proceder al entrenamiento, la red sale del metodo ya compilada y lista para ser entrenada, por lo que unicamente tenemos que preparar los Callbacks de Keras utilizados para tunear el modelo y lanzar el entrenamiento. Una vez finalizado, guardamos los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               min_delta=1e-4)]\n",
    "\n",
    "entrenamiento = model.fit(X_train, y_train, batch_size=16, epochs=100, callbacks=callbacks, validation_data=(X_test, y_test))          \n",
    "\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Una vez concluido el entrenamiento, lanzamos una grafica para comprobar como ha reducido la perdida de entrenamiento y validacion a lo largo de las iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ent_loss = entrenamiento.history['loss']\n",
    "val_loss = entrenamiento.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(ent_loss) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, ent_loss, 'b', label='Entrenamiento')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'r', label='Validación')\n",
    "plt.title('Pérdida en Entrenamiento y Validación')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, sacamos de una imagen, su groundtruth y la prediccion realizada de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig.add_subplot(1, 3,1)\n",
    "plt.imshow(X_test[0])\n",
    "fig.add_subplot(1,3 ,2)\n",
    "plt.imshow(np.argmax(y_test[0], axis=2))\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.imshow(np.argmax(predicted[0], axis=2))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
